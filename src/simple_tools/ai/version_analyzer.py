"""æ–‡ä»¶ç‰ˆæœ¬åˆ†æå™¨.

ç”¨äºåˆ†æé‡å¤æ–‡ä»¶ä¹‹é—´çš„ç‰ˆæœ¬å…³ç³»ï¼Œæä¾›æ™ºèƒ½ä¿ç•™å»ºè®®ã€‚
"""

import re
from datetime import datetime
from pathlib import Path
from typing import Any, Optional

import logfire
from pydantic import BaseModel, Field, computed_field

from ..ai.config import AIConfig
from ..ai.deepseek_client import DeepSeekClient, DeepSeekMessage
from ..ai.prompts import prompt_manager


class FileVersion(BaseModel):
    """æ–‡ä»¶ç‰ˆæœ¬ä¿¡æ¯."""

    path: Path
    size: int
    modified_time: float
    name_pattern: str = Field(default="", description="æ–‡ä»¶åæ¨¡å¼")
    version_indicator: Optional[str] = Field(None, description="ç‰ˆæœ¬æ ‡è¯†")
    content_preview: Optional[str] = Field(None, description="å†…å®¹é¢„è§ˆ")

    @computed_field
    @property
    def modified_datetime(self) -> datetime:
        """ä¿®æ”¹æ—¶é—´çš„datetimeå¯¹è±¡."""
        return datetime.fromtimestamp(self.modified_time)

    @computed_field
    @property
    def version_score(self) -> float:
        """ç‰ˆæœ¬è¯„åˆ†ï¼ˆè¶Šé«˜è¶Šå¯èƒ½æ˜¯æœ€æ–°ç‰ˆæœ¬ï¼‰."""
        score = 0.0

        # æ—¶é—´åˆ†æ•°ï¼ˆè¶Šæ–°åˆ†æ•°è¶Šé«˜ï¼‰
        time_score = self.modified_time / 1e10  # å½’ä¸€åŒ–
        score += time_score * 0.3

        # ç‰ˆæœ¬æ ‡è¯†åˆ†æ•°
        if self.version_indicator:
            if "final" in self.version_indicator.lower():
                score += 1.0
            elif "v" in self.version_indicator.lower():
                # æå–ç‰ˆæœ¬å·
                match = re.search(r"v?(\d+)(?:\.(\d+))?", self.version_indicator)
                if match:
                    major = int(match.group(1))
                    minor = int(match.group(2) or 0)
                    score += (major * 10 + minor) / 100.0
            elif any(
                word in self.version_indicator.lower()
                for word in ["new", "latest", "æœ€æ–°"]
            ):
                score += 0.8
            elif any(
                word in self.version_indicator.lower()
                for word in ["old", "backup", "å¤‡ä»½"]
            ):
                score -= 0.5

        # æ–‡ä»¶åæ¨¡å¼åˆ†æ•°
        if "å‰¯æœ¬" in self.name_pattern or "copy" in self.name_pattern.lower():
            score -= 0.3
        if "backup" in self.name_pattern.lower() or "å¤‡ä»½" in self.name_pattern:
            score -= 0.5

        return score


class VersionRelation(BaseModel):
    """ç‰ˆæœ¬å…³ç³»."""

    relation_type: str = Field(..., description="å…³ç³»ç±»å‹: version/backup/copy")
    confidence: float = Field(..., description="ç½®ä¿¡åº¦ 0-1")
    base_file: Path = Field(..., description="åŸºç¡€æ–‡ä»¶")
    derived_files: list[Path] = Field(..., description="æ´¾ç”Ÿæ–‡ä»¶")
    reason: str = Field(..., description="åˆ¤æ–­ç†ç”±")


class VersionAnalysis(BaseModel):
    """ç‰ˆæœ¬åˆ†æç»“æœ."""

    files: list[FileVersion]
    similarity_score: float = Field(..., description="å†…å®¹ç›¸ä¼¼åº¦ 0-1")
    has_version_relation: bool
    relation: Optional[VersionRelation] = None
    ai_suggestion: Optional[str] = None
    recommended_keep: Optional[Path] = None
    confidence: float = Field(0.0, description="å»ºè®®ç½®ä¿¡åº¦ 0-1")


class VersionAnalyzer:
    """æ–‡ä»¶ç‰ˆæœ¬åˆ†æå™¨."""

    def __init__(self, ai_config: Optional[AIConfig] = None):
        """åˆå§‹åŒ–ç‰ˆæœ¬åˆ†æå™¨."""
        self.ai_config = ai_config or AIConfig()
        self.ai_client = None
        if self.ai_config.enabled and self.ai_config.api_key:
            self.ai_client = DeepSeekClient(self.ai_config)

    def analyze_file_group(self, file_paths: list[Path]) -> VersionAnalysis:
        """åˆ†æä¸€ç»„æ–‡ä»¶çš„ç‰ˆæœ¬å…³ç³».

        Args:
            file_paths: æ–‡ä»¶è·¯å¾„åˆ—è¡¨

        Returns:
            ç‰ˆæœ¬åˆ†æç»“æœ

        """
        with logfire.span(
            "analyze_file_group", attributes={"file_count": len(file_paths)}
        ):
            # æ”¶é›†æ–‡ä»¶ä¿¡æ¯
            file_versions = self._collect_file_info(file_paths)

            # è®¡ç®—æ–‡ä»¶åç›¸ä¼¼åº¦
            similarity_score = self._calculate_name_similarity(file_versions)

            # è¯†åˆ«ç‰ˆæœ¬å…³ç³»
            has_relation, relation = self._identify_version_relation(file_versions)

            # åŸºç¡€åˆ†æç»“æœ
            analysis = VersionAnalysis(
                files=file_versions,
                similarity_score=similarity_score,
                has_version_relation=has_relation,
                relation=relation,
            )

            # ç”ŸæˆåŸºç¡€å»ºè®®
            analysis.recommended_keep = self._generate_basic_recommendation(
                file_versions
            )
            analysis.confidence = 0.7 if has_relation else 0.5

            return analysis

    async def analyze_with_ai(self, file_paths: list[Path]) -> VersionAnalysis:
        """ä½¿ç”¨AIåˆ†ææ–‡ä»¶ç‰ˆæœ¬å…³ç³».

        Args:
            file_paths: æ–‡ä»¶è·¯å¾„åˆ—è¡¨

        Returns:
            å¢å¼ºçš„ç‰ˆæœ¬åˆ†æç»“æœ

        """
        # å…ˆè¿›è¡ŒåŸºç¡€åˆ†æ
        analysis = self.analyze_file_group(file_paths)

        if not self.ai_client:
            return analysis

        try:
            # å‡†å¤‡AIåˆ†ææ•°æ®
            files_info = self._prepare_ai_files_info(analysis.files)

            # æ„å»ºAIæç¤º
            prompt = self._build_ai_prompt(files_info, analysis)

            # è°ƒç”¨AIè·å–å“åº”
            ai_result = await self._call_ai_for_analysis(prompt)

            # æ›´æ–°åˆ†æç»“æœ
            self._update_analysis_with_ai_result(analysis, ai_result)

            logfire.info(
                "AIç‰ˆæœ¬åˆ†æå®Œæˆ",
                attributes={
                    "file_count": len(file_paths),
                    "recommended": str(analysis.recommended_keep),
                    "confidence": analysis.confidence,
                },
            )

        except Exception as e:
            logfire.error(f"AIç‰ˆæœ¬åˆ†æå¤±è´¥: {e}")
            # ä¿æŒåŸºç¡€åˆ†æç»“æœ

        return analysis

    def _collect_file_info(self, file_paths: list[Path]) -> list[FileVersion]:
        """æ”¶é›†æ–‡ä»¶ä¿¡æ¯."""
        versions = []
        for path in file_paths:
            try:
                stat = path.stat()
                version = FileVersion(
                    path=path,
                    size=stat.st_size,
                    modified_time=stat.st_mtime,
                    name_pattern=self._extract_name_pattern(path.name),
                    version_indicator=self._extract_version_indicator(path.name),
                )
                versions.append(version)
            except Exception as e:
                logfire.warning(f"æ— æ³•è·å–æ–‡ä»¶ä¿¡æ¯: {path} - {e}")

        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
        versions.sort(key=lambda v: v.modified_time, reverse=True)
        return versions

    def _extract_name_pattern(self, filename: str) -> str:
        """æå–æ–‡ä»¶åæ¨¡å¼."""
        # ç§»é™¤ç‰ˆæœ¬å·
        pattern = re.sub(r"[_-]?v?\d+(?:\.\d+)?", "", filename, flags=re.IGNORECASE)
        # ç§»é™¤æ—¥æœŸ
        pattern = re.sub(r"\d{4}[-_]?\d{2}[-_]?\d{2}", "", pattern)
        # ç§»é™¤æ‹¬å·å†…å®¹
        pattern = re.sub(r"\([^)]+\)", "", pattern)
        pattern = re.sub(r"\[[^\]]+\]", "", pattern)
        return pattern.strip()

    def _extract_version_indicator(self, filename: str) -> Optional[str]:
        """æå–ç‰ˆæœ¬æ ‡è¯†."""
        # æŸ¥æ‰¾ç‰ˆæœ¬å·
        version_match = re.search(r"v?(\d+(?:\.\d+)?)", filename, re.IGNORECASE)
        if version_match:
            return version_match.group(0)

        # æŸ¥æ‰¾ç‰¹æ®Šæ ‡è¯†
        indicators = [
            "final",
            "æœ€ç»ˆ",
            "latest",
            "æœ€æ–°",
            "new",
            "old",
            "å¤‡ä»½",
            "backup",
            "copy",
            "å‰¯æœ¬",
        ]
        for indicator in indicators:
            if indicator in filename.lower():
                return indicator

        # æŸ¥æ‰¾æ—¥æœŸ
        date_match = re.search(r"(\d{4}[-_]?\d{2}[-_]?\d{2})", filename)
        if date_match:
            return date_match.group(0)

        return None

    def _calculate_name_similarity(self, versions: list[FileVersion]) -> float:
        """è®¡ç®—æ–‡ä»¶åç›¸ä¼¼åº¦."""
        if len(versions) < 2:
            return 0.0

        # è·å–æ‰€æœ‰æ–‡ä»¶åæ¨¡å¼
        patterns = [v.name_pattern for v in versions]

        # è®¡ç®—å¹³å‡ç›¸ä¼¼åº¦
        total_similarity = 0.0
        comparisons = 0

        for i in range(len(patterns)):
            for j in range(i + 1, len(patterns)):
                similarity = self._string_similarity(patterns[i], patterns[j])
                total_similarity += similarity
                comparisons += 1

        return total_similarity / comparisons if comparisons > 0 else 0.0

    def _string_similarity(self, s1: str, s2: str) -> float:
        """è®¡ç®—å­—ç¬¦ä¸²ç›¸ä¼¼åº¦ï¼ˆç®€å•å®ç°ï¼‰."""
        if not s1 or not s2:
            return 0.0

        # è½¬æ¢ä¸ºå°å†™
        s1, s2 = s1.lower(), s2.lower()

        # å¦‚æœå®Œå…¨ç›¸åŒ
        if s1 == s2:
            return 1.0

        # è®¡ç®—å…¬å…±å­ä¸²é•¿åº¦
        common_len = 0
        for char in set(s1):
            common_len += min(s1.count(char), s2.count(char))

        # ç›¸ä¼¼åº¦ = å…¬å…±å­—ç¬¦æ•° / å¹³å‡é•¿åº¦
        avg_len = (len(s1) + len(s2)) / 2
        return common_len / avg_len if avg_len > 0 else 0.0

    def _identify_version_relation(
        self, versions: list[FileVersion]
    ) -> tuple[bool, Optional[VersionRelation]]:
        """è¯†åˆ«ç‰ˆæœ¬å…³ç³»."""
        if len(versions) < 2:
            return False, None

        # æ£€æŸ¥æ˜¯å¦æœ‰æ˜æ˜¾çš„ç‰ˆæœ¬æ ‡è¯†
        has_version_indicators = any(v.version_indicator for v in versions)
        if not has_version_indicators:
            return False, None

        # æŒ‰ç‰ˆæœ¬åˆ†æ•°æ’åº
        sorted_versions = sorted(versions, key=lambda v: v.version_score, reverse=True)

        # ç¡®å®šåŸºç¡€æ–‡ä»¶ï¼ˆåˆ†æ•°æœ€é«˜çš„ï¼‰
        base_file = sorted_versions[0]
        derived_files = sorted_versions[1:]

        # åˆ¤æ–­å…³ç³»ç±»å‹
        relation_type = "version"  # é»˜è®¤ä¸ºç‰ˆæœ¬å…³ç³»
        confidence = 0.7

        # æ£€æŸ¥æ˜¯å¦ä¸ºå¤‡ä»½å…³ç³»
        if any(
            "backup" in str(f.path).lower() or "å¤‡ä»½" in str(f.path)
            for f in derived_files
        ):
            relation_type = "backup"
            confidence = 0.9

        # æ£€æŸ¥æ˜¯å¦ä¸ºå‰¯æœ¬å…³ç³»
        elif any(
            "copy" in str(f.path).lower() or "å‰¯æœ¬" in str(f.path)
            for f in derived_files
        ):
            relation_type = "copy"
            confidence = 0.85

        # æ„å»ºå…³ç³»
        relation = VersionRelation(
            relation_type=relation_type,
            confidence=confidence,
            base_file=base_file.path,
            derived_files=[f.path for f in derived_files],
            reason=f"åŸºäºæ–‡ä»¶åæ¨¡å¼å’Œä¿®æ”¹æ—¶é—´åˆ¤æ–­ä¸º{relation_type}å…³ç³»",
        )

        return True, relation

    def _prepare_ai_files_info(self, files: list[FileVersion]) -> list[dict[str, Any]]:
        """å‡†å¤‡AIåˆ†ææ‰€éœ€çš„æ–‡ä»¶ä¿¡æ¯."""
        files_info = []
        for fv in files:
            info = {
                "name": fv.path.name,
                "size": fv.size,
                "modified": fv.modified_datetime.isoformat(),
                "version_indicator": fv.version_indicator or "æ— ",
            }
            # å¦‚æœå¯èƒ½ï¼Œè¯»å–æ–‡ä»¶å¼€å¤´
            if fv.path.suffix in [".txt", ".md", ".json", ".yml", ".yaml"]:
                try:
                    with open(fv.path, encoding="utf-8") as f:
                        info["preview"] = f.read(200)
                except Exception:
                    pass
            files_info.append(info)
        return files_info

    def _build_ai_prompt(
        self, files_info: list[dict[str, Any]], analysis: VersionAnalysis
    ) -> str:
        """æ„å»ºAIåˆ†ææç¤º."""
        return prompt_manager.format(
            "version_analysis",
            files=files_info,
            basic_analysis={
                "similarity": analysis.similarity_score,
                "has_relation": analysis.has_version_relation,
                "relation_type": (
                    analysis.relation.relation_type if analysis.relation else None
                ),
            },
        )

    async def _call_ai_for_analysis(self, prompt: str) -> dict[str, Any]:
        """è°ƒç”¨AIè¿›è¡Œåˆ†æ."""
        messages = [DeepSeekMessage(role="user", content=prompt)]
        if not self.ai_client:
            return {}

        response = await self.ai_client.chat_completion(
            messages,
            temperature=0.3,  # é™ä½æ¸©åº¦ä»¥è·å¾—æ›´ä¸€è‡´çš„åˆ†æ
        )

        # è§£æAIå“åº”
        import json

        try:
            # å“åº”å¯èƒ½ç›´æ¥åŒ…å«analysiså­—æ®µï¼Œæˆ–è€…éœ€è¦ä»contentä¸­è§£æ
            if hasattr(response, "content"):
                response_data = json.loads(response.content)
            elif isinstance(response, dict):
                response_data = response
            else:
                # å¦‚æœå“åº”ç±»å‹ä¸ç¬¦åˆé¢„æœŸï¼Œè¿”å›ç©ºå­—å…¸
                return {}

            # ç¡®ä¿response_dataæ˜¯å­—å…¸ç±»å‹
            if not isinstance(response_data, dict):
                return {}

            # è·å–analysiså­—æ®µï¼Œç¡®ä¿è¿”å›dictç±»å‹
            analysis_data = response_data.get("analysis", {})
            # ç¡®ä¿è¿”å›å€¼æ˜¯dict[str, Any]ç±»å‹
            if isinstance(analysis_data, dict):
                return analysis_data
            else:
                return {}

        except (json.JSONDecodeError, AttributeError):
            # å¦‚æœAIè¿”å›çš„ä¸æ˜¯JSONï¼Œå°±ä½¿ç”¨é»˜è®¤å€¼
            return {}

    def _update_analysis_with_ai_result(
        self, analysis: VersionAnalysis, ai_result: dict[str, Any]
    ) -> None:
        """ä½¿ç”¨AIç»“æœæ›´æ–°åˆ†æ."""
        # æ›´æ–°æ¨èæ–‡ä»¶
        if ai_result.get("recommended_file"):
            for fv in analysis.files:
                if fv.path.name == ai_result["recommended_file"]:
                    analysis.recommended_keep = fv.path
                    break

        # è®¾ç½®AIå»ºè®®å’Œç½®ä¿¡åº¦
        analysis.ai_suggestion = ai_result.get("reason", None)
        if ai_result.get("confidence") is not None:
            analysis.confidence = float(ai_result["confidence"])

    def _generate_basic_recommendation(self, versions: list[FileVersion]) -> Path:
        """ç”ŸæˆåŸºç¡€æ¨è."""
        # æŒ‰ç‰ˆæœ¬åˆ†æ•°æ’åºï¼Œé€‰æ‹©åˆ†æ•°æœ€é«˜çš„
        sorted_versions = sorted(versions, key=lambda v: v.version_score, reverse=True)
        return sorted_versions[0].path

    def format_analysis_result(self, analysis: VersionAnalysis) -> str:
        """æ ¼å¼åŒ–åˆ†æç»“æœä¸ºå‹å¥½çš„å±•ç¤ºæ–‡æœ¬."""
        lines = []

        if analysis.has_version_relation and analysis.relation:
            lines.append(f"ğŸ“Š ç‰ˆæœ¬å…³ç³»: {analysis.relation.relation_type}")
            lines.append(f"   åŸºç¡€æ–‡ä»¶: {analysis.relation.base_file.name}")
            lines.append(f"   ç›¸å…³æ–‡ä»¶: {len(analysis.relation.derived_files)} ä¸ª")
            lines.append(f"   ç½®ä¿¡åº¦: {analysis.relation.confidence:.0%}")
            lines.append("")

        # æ ¼å¼åŒ–æ¨èä¿ç•™çš„æ–‡ä»¶å
        recommended_file = (
            analysis.recommended_keep.name if analysis.recommended_keep else "æ— "
        )
        lines.append(f"ğŸ’¡ AI å»ºè®®ä¿ç•™: {recommended_file}")
        if analysis.ai_suggestion:
            lines.append(f"   ç†ç”±: {analysis.ai_suggestion}")
        lines.append(f"   ç½®ä¿¡åº¦: {analysis.confidence:.0%}")

        return "\n".join(lines)
